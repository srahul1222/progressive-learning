{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FTE/BTE Experiment for DTD\n",
    "\n",
    "The progressive learning package utilizes representation ensembling algorithms to sequentially learn a representation for each task and ensemble both old and new representations for all future decisions. \n",
    "\n",
    "Here, a representation ensembling algorithm based on decision forests (Lifelong Forest) demonstrates forward and backward knowledge transfer of tasks on the Describable Textures Dataset (DTD). The original dataset can be found at https://www.robots.ox.ac.uk/~vgg/data/dtd/.\n",
    "\n",
    "### Import necessary packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental Set-up\n",
    "\n",
    "DTD has 47 classes of food with 120 images each. For the purposes of this experiment, only 40 of those classes are used. The dataset is split into 10 tasks with 4 classes each. \n",
    "\n",
    "Each class is then split into 4 batches of 30 images each. Every time the experiment is repeated, the batch used as the test set is shifted.\n",
    "\n",
    "The remaining 90 images in each class are further split into 3 batches containing 30 images each. Every time the experiment is repeated, the batch used for training each task is shifted. Originally, the first 30 images from each class are used for training, then the second 30 images from each class, then the third 90 images.\n",
    "\n",
    "With 4 batches of test sets and 3 batches of training sets, the number of permutations comes out to 12, so the final errors are averaged across 12 trials and then used to calculate FTE and BTE\n",
    "\n",
    "![](attachment:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTD Data Generation\n",
    "\n",
    "DTD was downloaded and preprocessed (images were padded and resized) by running the algorithms found in https://github.com/neurodata/LLF_tidy_images. This sectipn of the notebook serves to take those processed images and convert them into numpy arrays that can be read and used by the progressive learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set\n",
    "data_dir = \"../../../datasets_resized_wLabels/dtd/images\" # replace with the path name for wherever the downloaded dtd images have been stored\n",
    "textures_sorted = sorted(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start reading the image data into numpy arrays. Only the first 40 out of the 47 sorted texture classes will be used in order to make it easier to split up the samples into tasks later on.\n",
    "\n",
    "This process of initializing each x data array with some images and then concatenating to get the next batch of 1200 images is repeated 4 times, resulting in 4 numpy arrays each containing all the images from 10 of the dtd classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_x = {}\n",
    "for k in range(4):\n",
    "    # Initialize data_x* with the first image in the first class, then concatenate to acquire all images from the first class\n",
    "    texture_class = os.listdir(os.path.join(data_dir,textures_sorted[10*k]))\n",
    "    data_xk = [plt.imread(os.path.join(data_dir, textures_sorted[10*k], texture_class[0]))]\n",
    "\n",
    "    for i in range(1,120):\n",
    "            data_xk = np.concatenate([data_xk, [(plt.imread(os.path.join(data_dir, textures_sorted[10*k], texture_class[i])))]])\n",
    "\n",
    "    # Add to the initialized data_x* array until it contains all images from the 10 classes\n",
    "    # Concatenating more than 1200 images per batch increases the run time by a lot\n",
    "    for j in range(((k*10)+1),(10*(k+1))):\n",
    "        texture_class = os.listdir(os.path.join(data_dir,textures_sorted[j]))\n",
    "        for i in range(0,120):\n",
    "            data_xk = np.concatenate([data_xk, [(plt.imread(os.path.join(data_dir, textures_sorted[j], texture_class[i])))]])\n",
    "            \n",
    "    dict_x['data_x' + str(k+1)] = data_xk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine individual numpy arrays for x data for each batch of 10 classes all into one big numpy array\n",
    "data_x = np.concatenate([dict_x['data_x1'], dict_x['data_x2'], dict_x['data_x3']])\n",
    "data_x = np.concatenate([data_x, dict_x['data_x4']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create y data containing 40 class labels\n",
    "data_y = np.full((120), 0, dtype=int)\n",
    "for i in range(1,40):\n",
    "    data_y = np.concatenate([data_y, np.full((120), i, dtype=int)])\n",
    "print(data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model and perform validation\n",
    "\n",
    "`which_task`: The task number for which BTE should be calculated\n",
    "\n",
    "#### run_parallel_exp: \n",
    "Wrapper method for the `run_bte_exp` function which declares and trains the model, and performs validation with respect to the test data to compute the error of the model at a particular iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.fte_bte_dtd_functions import run_fte_bte_exp\n",
    "\n",
    "fte = []\n",
    "bte = []\n",
    "te = []\n",
    "accuracies = []\n",
    "\n",
    "for which_task in range(1,11):\n",
    "    \n",
    "    def run_parallel_exp(shift):\n",
    "    \n",
    "        df_list = run_fte_bte_exp(data_x, data_y, which_task, shift = shift)\n",
    "\n",
    "        return df_list\n",
    "\n",
    "    shifts = np.arange(0,4,1)\n",
    "    acc = []\n",
    "\n",
    "    with Pool(8) as p:\n",
    "        # Paralell processing to run the experiment using a different batch for the test set each time\n",
    "        acc.append(\n",
    "            p.map(run_parallel_exp, shifts)\n",
    "        )\n",
    "    \n",
    "    # Average forward transfer accuracies accross all permutations of testing and training batches for each task\n",
    "    acc_x = []\n",
    "    acc_y = []\n",
    "    acc_z = []\n",
    "    for z in range(which_task):\n",
    "        for y in range(4):\n",
    "            for x in range(3):\n",
    "                acc_x.append(acc[0][x][y]['task_accuracy'][z])\n",
    "            acc_y.append(np.mean(acc_x))\n",
    "            acc_x = []\n",
    "        acc_z.append(np.mean(acc_y))\n",
    "        acc_y = []\n",
    "        \n",
    "    # Calculate and store FTE\n",
    "    fte.append((1-acc_z[0])/(1-acc_z[-1]))\n",
    "    \n",
    "    # Average backward transfer accuracies accross all permutations of testing and training batches for each task\n",
    "    acc_x = []\n",
    "    acc_y = []\n",
    "    acc_z = []\n",
    "    for z in range((which_task - 1), 10):\n",
    "        for y in range(4):\n",
    "            for x in range(3):\n",
    "                acc_x.append(acc[0][x][y]['task_accuracy'][z])\n",
    "            acc_y.append(np.mean(acc_x))\n",
    "            acc_x = []\n",
    "        acc_z.append(np.mean(acc_y))\n",
    "        acc_y = []\n",
    "        \n",
    "    # Calculate and store accuracies, BTE, and TE\n",
    "    accuracies.append(acc_z)\n",
    "    calc_bte = (1-acc_z[0])/([1-a for a in acc_z])\n",
    "    bte.append(calc_bte)\n",
    "    te.append([fte[(which_task-1)]*a for a in calc_bte])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating FTE, BTE, TE, and Accuracy\n",
    "\n",
    "The forward transfer efficiency of $f$ for task $t$ given $n$ samples is \n",
    "$$FTE_n^t (f) := \\mathbb{E} [R^t (f(D_n^{t}) )] / \\mathbb{E} [R^t (f(D_n^{<t}))]$$\n",
    "\n",
    "We say an algorithm achieves forward transfer for task $t$ if and only if $FTE_n^t(f) > 1$. Intuitively, this means that the progressive learner has used data associated with past tasks to improve performance on task $t$. \n",
    "\n",
    "The backward transfer efficiency of $f$ for task $t$ given $n$ samples is \n",
    "$$BTE_n^t (f) := \\mathbb{E} [R^t (f(D_n^{<t}) )] / \\mathbb{E} [R^t (f(D_n))]$$\n",
    "\n",
    "We say an algorithm achieves backward transfer for task $t$ if and only if $BTE_n^t(f) > 1$. Intuitively, this means that the progressive learner has used data associated with new tasks to improve performance on previous tasks. \n",
    "\n",
    "The transfer efficiency of $f$ for task $t$ given $n$ samples is \n",
    "$$TE_n^t (f) := \\mathbb{E} [R^t (f(D_n^{t}) )] / \\mathbb{E} [R^t (f(D_n))]$$\n",
    "\n",
    "We say an algorithm has transfer learned for task $t$ with data $D_n$ if and only if $TE_n^t(f) > 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting FTE, BTE, TE, and Accuracy\n",
    "Run cell to generate a figure containing 4 plots of the forward transfer efficiency, backward transfer efficiency, transfer efficiency, and accuracy of the Lifelong Classification Forest algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "n_tasks=10\n",
    "clr = [\"#e41a1c\", \"#a65628\", \"#377eb8\", \"#4daf4a\", \"#984ea3\", \"#ff7f00\", \"#CCCC00\"]\n",
    "#c = sns.color_palette(clr, n_colors=len(clr))\n",
    "\n",
    "fontsize=22\n",
    "ticksize=20\n",
    "\n",
    "# Plot FTE\n",
    "\n",
    "fig, ax = plt.subplots(2,2, figsize=(16,11.5))\n",
    "#fig.suptitle('ntrees = '+str(ntrees),fontsize=25)\n",
    "ax[0][0].plot(np.arange(1,n_tasks+1), fte, c='red', marker='.', markersize=14, linewidth=3)\n",
    "ax[0][0].hlines(1, 1,n_tasks, colors='grey', linestyles='dashed',linewidth=1.5)\n",
    "ax[0][0].tick_params(labelsize=ticksize)\n",
    "ax[0][0].set_xlabel('Number of tasks seen', fontsize=fontsize)\n",
    "ax[0][0].set_ylabel('FTE', fontsize=fontsize)\n",
    "\n",
    "# Plot BTE\n",
    "\n",
    "for i in range(n_tasks):\n",
    "\n",
    "    et = np.asarray(bte[i])\n",
    "\n",
    "    ns = np.arange(i + 1, n_tasks + 1)\n",
    "    ax[0][1].plot(ns, et, c='red', linewidth = 2.6)\n",
    "    \n",
    "ax[0][1].set_xlabel('Number of tasks seen', fontsize=fontsize)\n",
    "ax[0][1].set_ylabel('BTE', fontsize=fontsize)\n",
    "#ax[0][1].set_xticks(np.arange(1,10))\n",
    "ax[0][1].tick_params(labelsize=ticksize)\n",
    "ax[0][1].hlines(1, 1,n_tasks, colors='grey', linestyles='dashed',linewidth=1.5)\n",
    "\n",
    "# Plot TE\n",
    "\n",
    "for i in range(n_tasks):\n",
    "\n",
    "    et = np.asarray(te[i])\n",
    "\n",
    "    ns = np.arange(i + 1, n_tasks + 1)\n",
    "    ax[1][0].plot(ns, et, c='red', linewidth = 2.6)\n",
    "    \n",
    "ax[1][0].set_xlabel('Number of tasks seen', fontsize=fontsize)\n",
    "ax[1][0].set_ylabel('Transfer Efficiency', fontsize=fontsize)\n",
    "#ax[1][0].set_xticks(np.arange(1,10))\n",
    "ax[1][0].tick_params(labelsize=ticksize)\n",
    "ax[1][0].hlines(1, 1,n_tasks, colors='grey', linestyles='dashed',linewidth=1.5)\n",
    "\n",
    "# Plot accuracy\n",
    "\n",
    "for i in range(n_tasks):\n",
    "    acc_p = np.asarray(accuracies[i])\n",
    "    ns = np.arange(i + 1, n_tasks + 1)\n",
    "\n",
    "    ax[1][1].plot(ns, acc_p , c='red', linewidth = 2.6)\n",
    "            \n",
    "#ax[1][1].legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=22)\n",
    "ax[1][1].set_xlabel('Number of tasks seen', fontsize=fontsize)\n",
    "ax[1][1].set_ylabel('Accuracy', fontsize=fontsize)\n",
    "ax[1][1].tick_params(labelsize=ticksize)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
